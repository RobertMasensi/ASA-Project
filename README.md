# ASA-Project
This project aims to gather up data from a csv zipe file and then create an ETL pipeline using Python Jupyter Notebook and Snowflake Connector.
The project will aim to first extract the data from the csv zip file; thereafter cleaning the data, in separate dataframes, in Python Jupyter Notebook.
Once the cleaning process finishes, the Snowflake Connector will be used to update the dataframes into an instance of Snowflake for analysis.

The project's timeline will go as follow:
  1) Data Extraction.
  2) Data Standardization.
  3) Data Cleaning.
  4) Data Normalization.
  5) Snowflake Connection.
  6) Schema Execution for the various dataframes.
  7) Loading of the dataframes onto Snowflake.
  8) Verify that the ETL scripts were successful through Querying the data in Snowflake.
